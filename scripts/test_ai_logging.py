#!/usr/bin/env python3
"""
AIè°ƒç”¨æ—¥å¿—è®°å½•åŠŸèƒ½æµ‹è¯•è„šæœ¬
æµ‹è¯•æ–°å¢çš„AIè°ƒç”¨è¯¦ç»†æ—¥å¿—è®°å½•åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import tempfile
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from tradingagents.utils.ai_call_logger import log_ai_call, log_ai_debug
from tradingagents.utils.llm_enhancer import enhance_llm_with_logging
from tradingagents.utils.logging_init import get_logger

# è®¾ç½®æ—¥å¿—
logger = get_logger("ai_logging_test")

def test_ai_call_decorator():
    """æµ‹è¯•AIè°ƒç”¨è£…é¥°å™¨"""

    logger.info("ğŸ§ª [æµ‹è¯•å¼€å§‹] AIè°ƒç”¨è£…é¥°å™¨åŸºç¡€åŠŸèƒ½æµ‹è¯•")

    @log_ai_call(provider="test", model="test-model", log_input=True, log_output=True)
    def mock_ai_call(messages, temperature=0.1, **kwargs):
        """æ¨¡æ‹ŸAIè°ƒç”¨"""
        logger.info(f"ğŸ“ [æ¨¡æ‹ŸAIè°ƒç”¨] æ”¶åˆ° {len(messages)} æ¡æ¶ˆæ¯ï¼Œæ¸©åº¦ï¼š{temperature}")

        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
        import time
        time.sleep(0.1)

        # æ¨¡æ‹Ÿè¿”å›ç»“æœ
        class MockResponse:
            def __init__(self, content):
                self.content = content
                self.additional_kwargs = {}

        return MockResponse("è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•AIå“åº”")

    # æµ‹è¯•è°ƒç”¨
    test_messages = [
        {"content": "ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ¶ˆæ¯"},
        {"content": "è¯·åˆ†æä¸€ä¸‹è‚¡ç¥¨AAPL"}
    ]

    try:
        result = mock_ai_call(
            messages=test_messages,
            temperature=0.2,
            session_id="test_session_001",
            analysis_type="test_analysis"
        )

        logger.info(f"âœ… [æµ‹è¯•æˆåŠŸ] AIè°ƒç”¨è£…é¥°å™¨æµ‹è¯•é€šè¿‡ï¼Œè¿”å›ç»“æœï¼š{result.content[:50]}...")
        return True

    except Exception as e:
        logger.error(f"âŒ [æµ‹è¯•å¤±è´¥] AIè°ƒç”¨è£…é¥°å™¨æµ‹è¯•å¤±è´¥ï¼š{e}")
        return False


def test_mock_llm_enhancement():
    """æµ‹è¯•LLMå¢å¼ºå™¨åŠŸèƒ½ï¼ˆä½¿ç”¨æ¨¡æ‹ŸLLMï¼‰"""

    logger.info("ğŸ§ª [æµ‹è¯•å¼€å§‹] LLMå¢å¼ºå™¨åŠŸèƒ½æµ‹è¯•")

    class MockLLM:
        def __init__(self, model="mock-model"):
            self.model = model
            self.model_name = model

        def _generate(self, messages, **kwargs):
            """æ¨¡æ‹Ÿ_generateæ–¹æ³•"""
            logger.info(f"ğŸ“ [æ¨¡æ‹ŸLLM] _generateè¢«è°ƒç”¨ï¼Œæ¶ˆæ¯æ•°é‡ï¼š{len(messages)}")

            class MockChatResult:
                def __init__(self):
                    self.generations = [self.MockGeneration()]
                    self.llm_output = {
                        'token_usage': {
                            'prompt_tokens': 50,
                            'completion_tokens': 30,
                            'total_tokens': 80
                        }
                    }

                class MockGeneration:
                    def __init__(self):
                        self.message = self.MockMessage()

                    class MockMessage:
                        def __init__(self):
                            self.content = "è¿™æ˜¯æ¨¡æ‹Ÿçš„AIå“åº”å†…å®¹ï¼Œç”¨äºæµ‹è¯•æ—¥å¿—è®°å½•åŠŸèƒ½ã€‚"

            return MockChatResult()

        def invoke(self, input_data, **kwargs):
            """æ¨¡æ‹Ÿinvokeæ–¹æ³•"""
            logger.info(f"ğŸ“ [æ¨¡æ‹ŸLLM] invokeè¢«è°ƒç”¨ï¼Œè¾“å…¥ç±»å‹ï¼š{type(input_data)}")

            class MockAIMessage:
                def __init__(self, content):
                    self.content = content
                    self.additional_kwargs = {}

            return MockAIMessage("æ¨¡æ‹Ÿçš„invokeå“åº”")

    try:
        # åˆ›å»ºæ¨¡æ‹ŸLLMå®ä¾‹
        mock_llm = MockLLM("test-mock-model")

        # ä½¿ç”¨å¢å¼ºå™¨å¢å¼ºæ¨¡æ‹ŸLLM
        enhanced_llm = enhance_llm_with_logging(
            llm_instance=mock_llm,
            provider="mock",
            model="test-mock-model",
            enable_detailed_logging=True
        )

        # æµ‹è¯•_generateæ–¹æ³•
        test_messages = [
            {"content": "æµ‹è¯•æ¶ˆæ¯1"},
            {"content": "æµ‹è¯•æ¶ˆæ¯2"}
        ]

        result1 = enhanced_llm._generate(
            messages=test_messages,
            session_id="test_session_002",
            analysis_type="mock_test"
        )

        logger.info(f"âœ… [æµ‹è¯•æˆåŠŸ] _generateæ–¹æ³•å¢å¼ºæµ‹è¯•é€šè¿‡")

        # æµ‹è¯•invokeæ–¹æ³•
        result2 = enhanced_llm.invoke(
            input_data="æµ‹è¯•invokeè°ƒç”¨",
            session_id="test_session_003",
            analysis_type="mock_invoke_test"
        )

        logger.info(f"âœ… [æµ‹è¯•æˆåŠŸ] invokeæ–¹æ³•å¢å¼ºæµ‹è¯•é€šè¿‡ï¼Œç»“æœï¼š{result2.content[:30]}...")

        return True

    except Exception as e:
        logger.error(f"âŒ [æµ‹è¯•å¤±è´¥] LLMå¢å¼ºå™¨æµ‹è¯•å¤±è´¥ï¼š{e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ï¼š{traceback.format_exc()}")
        return False


def test_debug_decorator():
    """æµ‹è¯•è°ƒè¯•æ¨¡å¼è£…é¥°å™¨"""

    logger.info("ğŸ§ª [æµ‹è¯•å¼€å§‹] è°ƒè¯•æ¨¡å¼è£…é¥°å™¨æµ‹è¯•")

    @log_ai_debug()
    def mock_complex_ai_call(*args, **kwargs):
        """æ¨¡æ‹Ÿå¤æ‚çš„AIè°ƒç”¨"""
        logger.info(f"ğŸ“ [æ¨¡æ‹Ÿå¤æ‚AIè°ƒç”¨] å‚æ•°ï¼š{len(args)} ä¸ªä½ç½®å‚æ•°ï¼Œ{len(kwargs)} ä¸ªå…³é”®å­—å‚æ•°")

        # æ¨¡æ‹Ÿå¤„ç†
        import time
        time.sleep(0.05)

        return {
            "status": "success",
            "data": "è¿™æ˜¯å¤æ‚AIè°ƒç”¨çš„è¿”å›ç»“æœ",
            "metadata": {
                "processing_time": "0.05s",
                "tokens_used": 75
            }
        }

    try:
        result = mock_complex_ai_call(
            "å‚æ•°1", "å‚æ•°2",
            temperature=0.3,
            max_tokens=100,
            session_id="debug_test_001"
        )

        logger.info(f"âœ… [æµ‹è¯•æˆåŠŸ] è°ƒè¯•è£…é¥°å™¨æµ‹è¯•é€šè¿‡ï¼ŒçŠ¶æ€ï¼š{result['status']}")
        return True

    except Exception as e:
        logger.error(f"âŒ [æµ‹è¯•å¤±è´¥] è°ƒè¯•è£…é¥°å™¨æµ‹è¯•å¤±è´¥ï¼š{e}")
        return False


def test_real_trading_graph():
    """æµ‹è¯•çœŸå®çš„TradingGraph AIæ—¥å¿—è®°å½•ï¼ˆå¦‚æœç¯å¢ƒå…è®¸ï¼‰"""

    logger.info("ğŸ§ª [æµ‹è¯•å¼€å§‹] çœŸå®TradingGraph AIæ—¥å¿—è®°å½•æµ‹è¯•")

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„ç¯å¢ƒå˜é‡
        required_env_vars = ["DEEPSEEK_API_KEY", "OPENAI_API_KEY"]
        available_providers = []

        for env_var in required_env_vars:
            if os.getenv(env_var):
                if env_var == "DEEPSEEK_API_KEY":
                    available_providers.append("deepseek")
                elif env_var == "OPENAI_API_KEY":
                    available_providers.append("openai")

        if not available_providers:
            logger.warning("âš ï¸ [æµ‹è¯•è·³è¿‡] æ²¡æœ‰å¯ç”¨çš„AIæä¾›å•†APIå¯†é’¥ï¼Œè·³è¿‡çœŸå®TradingGraphæµ‹è¯•")
            return True

        logger.info(f"ğŸ”‘ [ç¯å¢ƒæ£€æŸ¥] å¯ç”¨çš„AIæä¾›å•†ï¼š{available_providers}")

        # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æä¾›å•†è¿›è¡Œæµ‹è¯•
        provider = available_providers[0]

        # å¯¼å…¥TradingGraph
        from tradingagents.graph.trading_graph import TradingAgentsGraph

        # é…ç½®
        test_config = {
            "llm_provider": provider,
            "deep_think_llm": "deepseek-chat" if provider == "deepseek" else "gpt-3.5-turbo",
            "quick_think_llm": "deepseek-chat" if provider == "deepseek" else "gpt-3.5-turbo",
            "backend_url": "https://api.deepseek.com" if provider == "deepseek" else "https://api.openai.com/v1",
            "project_dir": str(project_root),
            "memory_enabled": False,  # å…³é—­å†…å­˜ä»¥ç®€åŒ–æµ‹è¯•
            "parallel_analysts": False
        }

        logger.info(f"ğŸ—ï¸ [TradingGraph] åˆ›å»º {provider} TradingGraphå®ä¾‹...")

        # åˆ›å»ºTradingGraphå®ä¾‹
        graph = TradingAgentsGraph(
            selected_analysts=["market"],  # åªä½¿ç”¨ä¸€ä¸ªåˆ†æå¸ˆç®€åŒ–æµ‹è¯•
            debug=True,
            config=test_config
        )

        logger.info(f"âœ… [æµ‹è¯•æˆåŠŸ] TradingGraphå®ä¾‹åˆ›å»ºæˆåŠŸï¼ŒAIæ—¥å¿—å¢å¼ºå·²åº”ç”¨")

        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ ç®€å•çš„AIè°ƒç”¨æµ‹è¯•
        # ä½†ä¸ºäº†é¿å…äº§ç”Ÿå®é™…çš„APIè´¹ç”¨ï¼Œæˆ‘ä»¬åªæµ‹è¯•å®ä¾‹åŒ–

        return True

    except Exception as e:
        logger.error(f"âŒ [æµ‹è¯•å¤±è´¥] çœŸå®TradingGraphæµ‹è¯•å¤±è´¥ï¼š{e}")
        import traceback
        logger.error(f"è¯¦ç»†é”™è¯¯ï¼š{traceback.format_exc()}")
        return False


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""

    logger.info("ğŸš€ [æµ‹è¯•å¥—ä»¶å¼€å§‹] AIè°ƒç”¨æ—¥å¿—è®°å½•åŠŸèƒ½å®Œæ•´æµ‹è¯•")
    logger.info("=" * 60)

    tests = [
        ("AIè°ƒç”¨è£…é¥°å™¨åŸºç¡€åŠŸèƒ½", test_ai_call_decorator),
        ("LLMå¢å¼ºå™¨åŠŸèƒ½", test_mock_llm_enhancement),
        ("è°ƒè¯•æ¨¡å¼è£…é¥°å™¨", test_debug_decorator),
        ("çœŸå®TradingGraphé›†æˆ", test_real_trading_graph)
    ]

    passed_tests = 0
    total_tests = len(tests)

    for test_name, test_func in tests:
        logger.info(f"\nğŸ“‹ [æ‰§è¡Œæµ‹è¯•] {test_name}")
        logger.info("-" * 40)

        try:
            if test_func():
                logger.info(f"âœ… [æµ‹è¯•é€šè¿‡] {test_name}")
                passed_tests += 1
            else:
                logger.error(f"âŒ [æµ‹è¯•å¤±è´¥] {test_name}")
        except Exception as e:
            logger.error(f"âŒ [æµ‹è¯•å¼‚å¸¸] {test_name}ï¼š{e}")

    logger.info("=" * 60)
    logger.info(f"ğŸ [æµ‹è¯•ç»“æœ] é€šè¿‡ {passed_tests}/{total_tests} ä¸ªæµ‹è¯•")

    if passed_tests == total_tests:
        logger.info("ğŸ‰ [æ‰€æœ‰æµ‹è¯•é€šè¿‡] AIè°ƒç”¨æ—¥å¿—è®°å½•åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")
        return True
    else:
        logger.warning(f"âš ï¸ [éƒ¨åˆ†æµ‹è¯•å¤±è´¥] æœ‰ {total_tests - passed_tests} ä¸ªæµ‹è¯•å¤±è´¥")
        return False


if __name__ == "__main__":
    logger.info("ğŸ§ª [æµ‹è¯•å¯åŠ¨] AIè°ƒç”¨æ—¥å¿—è®°å½•åŠŸèƒ½æµ‹è¯•è„šæœ¬")
    logger.info(f"â° [æµ‹è¯•æ—¶é—´] {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ğŸ“ [é¡¹ç›®è·¯å¾„] {project_root}")

    success = run_all_tests()

    if success:
        logger.info("âœ… [æµ‹è¯•å®Œæˆ] æ‰€æœ‰æµ‹è¯•æˆåŠŸå®Œæˆ")
        sys.exit(0)
    else:
        logger.error("âŒ [æµ‹è¯•å¤±è´¥] éƒ¨åˆ†æˆ–å…¨éƒ¨æµ‹è¯•å¤±è´¥")
        sys.exit(1)