#!/usr/bin/env python3
"""
AIè°ƒç”¨è¯¦ç»†æ—¥å¿—è®°å½•å™¨
ä¸“é—¨ç”¨äºè®°å½•AIæ¨¡å‹è°ƒç”¨çš„è¯¦ç»†å‚æ•°ã€è¿”å›ç»“æœç­‰è°ƒè¯•ä¿¡æ¯
"""

import json
import time
import functools
import hashlib
from typing import Any, Dict, List, Optional, Callable, Union
from datetime import datetime
import traceback

from tradingagents.utils.logging_init import get_logger
from tradingagents.utils.logging_manager import get_logger_manager

# AIè°ƒç”¨ä¸“ç”¨æ—¥å¿—å™¨
ai_logger = get_logger("ai_calls")
logger_manager = get_logger_manager()


def truncate_text(text: str, max_length: int = 500) -> str:
    """å®‰å…¨åœ°æˆªæ–­æ–‡æœ¬ï¼Œé¿å…æ—¥å¿—è¿‡é•¿"""
    if not text:
        return ""

    text_str = str(text)
    if len(text_str) <= max_length:
        return text_str

    return text_str[:max_length] + f"... (æˆªæ–­ï¼Œæ€»é•¿åº¦: {len(text_str)})"


def safe_json_dumps(obj: Any) -> str:
    """å®‰å…¨åœ°åºåˆ—åŒ–å¯¹è±¡ä¸ºJSONï¼Œå¤„ç†ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡"""
    try:
        return json.dumps(obj, ensure_ascii=False, indent=2, default=str)
    except Exception:
        return str(obj)


def extract_message_info(messages: List) -> Dict:
    """æå–æ¶ˆæ¯ä¿¡æ¯ç”¨äºæ—¥å¿—è®°å½•"""
    if not messages:
        return {"count": 0, "types": [], "total_chars": 0}

    msg_info = {
        "count": len(messages),
        "types": [],
        "total_chars": 0,
        "messages_preview": []
    }

    for i, msg in enumerate(messages):
        if hasattr(msg, '__class__'):
            msg_type = msg.__class__.__name__
        else:
            msg_type = type(msg).__name__

        msg_info["types"].append(msg_type)

        # æå–æ¶ˆæ¯å†…å®¹
        content = ""
        if hasattr(msg, 'content'):
            content = str(msg.content)
        elif isinstance(msg, dict) and 'content' in msg:
            content = str(msg['content'])
        elif isinstance(msg, str):
            content = msg

        msg_info["total_chars"] += len(content)

        # æ·»åŠ å‰å‡ æ¡æ¶ˆæ¯çš„é¢„è§ˆï¼ˆæˆªæ–­ç‰ˆæœ¬ï¼‰
        if i < 3:
            msg_info["messages_preview"].append({
                "type": msg_type,
                "content": truncate_text(content, 200),
                "length": len(content)
            })

    return msg_info


def log_ai_call(
    provider: str,
    model: str = None,
    log_input: bool = True,
    log_output: bool = True,
    log_tokens: bool = True,
    debug_level: str = "INFO"
):
    """
    AIè°ƒç”¨è¯¦ç»†æ—¥å¿—è£…é¥°å™¨

    Args:
        provider: AIæä¾›å•†åç§°ï¼ˆå¦‚ï¼šopenaiã€deepseekã€anthropicç­‰ï¼‰
        model: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸æä¾›åˆ™å°è¯•ä»å®ä¾‹ä¸­è·å–
        log_input: æ˜¯å¦è®°å½•è¾“å…¥å‚æ•°è¯¦æƒ…
        log_output: æ˜¯å¦è®°å½•è¾“å‡ºç»“æœè¯¦æƒ…
        log_tokens: æ˜¯å¦è®°å½•tokenä½¿ç”¨æƒ…å†µ
        debug_level: æ—¥å¿—çº§åˆ«ï¼ˆDEBUGã€INFOã€WARNINGã€ERRORï¼‰
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # ç”Ÿæˆè°ƒç”¨IDç”¨äºè¿½è¸ª
            call_id = hashlib.md5(f"{time.time()}{func.__name__}".encode()).hexdigest()[:8]

            # è·å–æ¨¡å‹åç§°
            actual_model = model
            if not actual_model and args and hasattr(args[0], 'model_name'):
                actual_model = getattr(args[0], 'model_name', 'unknown')
            elif not actual_model and args and hasattr(args[0], 'model'):
                actual_model = getattr(args[0], 'model', 'unknown')

            start_time = time.time()

            # è®°å½•è°ƒç”¨å¼€å§‹
            call_info = {
                "call_id": call_id,
                "provider": provider,
                "model": actual_model or "unknown",
                "function": func.__name__,
                "start_time": datetime.now().isoformat(),
                "args_count": len(args),
                "kwargs_keys": list(kwargs.keys())
            }

            ai_logger.info(
                f"ğŸ¤– [AIè°ƒç”¨å¼€å§‹] {provider}/{actual_model} - {func.__name__} [ID: {call_id}]",
                extra=call_info
            )

            # è®°å½•è¯¦ç»†è¾“å…¥å‚æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if log_input:
                input_details = {}

                # å¤„ç†ä½ç½®å‚æ•°
                if args:
                    for i, arg in enumerate(args):
                        if i == 0:  # é€šå¸¸æ˜¯selfå®ä¾‹ï¼Œè·³è¿‡
                            continue
                        elif hasattr(arg, '__iter__') and not isinstance(arg, str):
                            # å¤„ç†æ¶ˆæ¯åˆ—è¡¨
                            try:
                                if hasattr(arg, '__len__') and len(arg) > 0:
                                    first_item = arg[0] if len(arg) > 0 else None
                                    if hasattr(first_item, 'content') or isinstance(first_item, dict):
                                        # è¿™çœ‹èµ·æ¥åƒæ¶ˆæ¯åˆ—è¡¨
                                        input_details[f"messages"] = extract_message_info(arg)
                                    else:
                                        input_details[f"arg_{i}"] = {
                                            "type": type(arg).__name__,
                                            "length": len(arg),
                                            "preview": truncate_text(str(arg), 100)
                                        }
                                else:
                                    input_details[f"arg_{i}"] = truncate_text(str(arg), 100)
                            except Exception:
                                input_details[f"arg_{i}"] = f"<{type(arg).__name__}>"
                        else:
                            input_details[f"arg_{i}"] = truncate_text(str(arg), 100)

                # å¤„ç†å…³é”®å­—å‚æ•°
                for key, value in kwargs.items():
                    if key in ['session_id', 'analysis_type', 'temperature', 'max_tokens']:
                        input_details[key] = value
                    else:
                        input_details[key] = truncate_text(str(value), 100)

                if input_details:
                    ai_logger.debug(
                        f"ğŸ“ [AIè°ƒç”¨è¾“å…¥] [ID: {call_id}] è¯¦ç»†å‚æ•°",
                        extra={
                            "call_id": call_id,
                            "event_type": "ai_input_details",
                            "input_details": input_details
                        }
                    )

            try:
                # æ‰§è¡ŒAIè°ƒç”¨
                result = func(*args, **kwargs)
                duration = time.time() - start_time

                # è®°å½•è°ƒç”¨æˆåŠŸ
                success_info = {
                    "call_id": call_id,
                    "provider": provider,
                    "model": actual_model or "unknown",
                    "function": func.__name__,
                    "duration": round(duration, 3),
                    "success": True,
                    "end_time": datetime.now().isoformat()
                }

                ai_logger.info(
                    f"âœ… [AIè°ƒç”¨æˆåŠŸ] {provider}/{actual_model} - {func.__name__} [ID: {call_id}] (è€—æ—¶: {duration:.2f}s)",
                    extra=success_info
                )

                # è®°å½•è¯¦ç»†è¾“å‡ºç»“æœï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if log_output and result is not None:
                    output_details = {}

                    # åˆ†æè¿”å›ç»“æœçš„ç±»å‹å’Œå†…å®¹
                    result_type = type(result).__name__
                    output_details["result_type"] = result_type

                    if hasattr(result, 'content'):
                        # LangChain AIMessage ç±»å‹
                        content = str(result.content)
                        output_details["content"] = truncate_text(content, 1000)
                        output_details["content_length"] = len(content)

                        # è®°å½•é™„åŠ ä¿¡æ¯
                        if hasattr(result, 'additional_kwargs'):
                            additional = result.additional_kwargs
                            if additional:
                                output_details["additional_kwargs"] = {
                                    key: truncate_text(str(value), 200)
                                    for key, value in additional.items()
                                }

                    elif hasattr(result, 'generations'):
                        # ChatResult ç±»å‹
                        output_details["generations_count"] = len(result.generations)
                        if result.generations:
                            first_gen = result.generations[0]
                            if hasattr(first_gen, 'message') and hasattr(first_gen.message, 'content'):
                                content = str(first_gen.message.content)
                                output_details["first_generation_content"] = truncate_text(content, 1000)
                                output_details["first_generation_length"] = len(content)

                        # è®°å½•LLMè¾“å‡ºä¿¡æ¯ï¼ˆåŒ…å«tokenä½¿ç”¨ï¼‰
                        if hasattr(result, 'llm_output') and result.llm_output:
                            llm_output = result.llm_output
                            output_details["llm_output"] = {}

                            # Tokenä½¿ç”¨ä¿¡æ¯
                            if 'token_usage' in llm_output:
                                token_usage = llm_output['token_usage']
                                output_details["token_usage"] = {
                                    "prompt_tokens": token_usage.get('prompt_tokens', 0),
                                    "completion_tokens": token_usage.get('completion_tokens', 0),
                                    "total_tokens": token_usage.get('total_tokens', 0)
                                }

                            # å…¶ä»–å…ƒä¿¡æ¯
                            for key, value in llm_output.items():
                                if key != 'token_usage':
                                    output_details["llm_output"][key] = truncate_text(str(value), 200)

                    else:
                        # å…¶ä»–ç±»å‹çš„ç»“æœ
                        result_str = str(result)
                        output_details["content"] = truncate_text(result_str, 1000)
                        output_details["content_length"] = len(result_str)

                    if output_details:
                        ai_logger.debug(
                            f"ğŸ“¤ [AIè°ƒç”¨è¾“å‡º] [ID: {call_id}] è¯¦ç»†ç»“æœ",
                            extra={
                                "call_id": call_id,
                                "event_type": "ai_output_details",
                                "output_details": output_details
                            }
                        )

                # è®°å½•Tokenä½¿ç”¨æƒ…å†µï¼ˆå¦‚æœå¯ç”¨ä¸”å¯ç”¨ï¼‰
                if log_tokens:
                    token_info = extract_token_usage(result, args, kwargs)
                    if token_info:
                        ai_logger.info(
                            f"ğŸ’° [Tokenä½¿ç”¨] [ID: {call_id}] è¾“å…¥: {token_info.get('input_tokens', 0)}, "
                            f"è¾“å‡º: {token_info.get('output_tokens', 0)}, "
                            f"æ€»è®¡: {token_info.get('total_tokens', 0)}, "
                            f"æˆæœ¬: Â¥{token_info.get('cost', 0.0):.6f}",
                            extra={
                                "call_id": call_id,
                                "event_type": "ai_token_usage",
                                **token_info
                            }
                        )

                return result

            except Exception as e:
                duration = time.time() - start_time

                # è®°å½•è°ƒç”¨å¤±è´¥
                error_info = {
                    "call_id": call_id,
                    "provider": provider,
                    "model": actual_model or "unknown",
                    "function": func.__name__,
                    "duration": round(duration, 3),
                    "success": False,
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "end_time": datetime.now().isoformat()
                }

                ai_logger.error(
                    f"âŒ [AIè°ƒç”¨å¤±è´¥] {provider}/{actual_model} - {func.__name__} [ID: {call_id}] "
                    f"(è€—æ—¶: {duration:.2f}s): {str(e)}",
                    extra=error_info,
                    exc_info=True
                )

                # è®°å½•è¯¦ç»†é”™è¯¯å †æ ˆ
                error_details = {
                    "call_id": call_id,
                    "event_type": "ai_error_details",
                    "traceback": traceback.format_exc(),
                    "error_args": [str(arg) for arg in e.args] if hasattr(e, 'args') else []
                }

                ai_logger.debug(
                    f"ğŸ” [AIè°ƒç”¨é”™è¯¯è¯¦æƒ…] [ID: {call_id}]",
                    extra=error_details
                )

                # é‡æ–°æŠ›å‡ºå¼‚å¸¸
                raise

        return wrapper
    return decorator


def extract_token_usage(result: Any, args: tuple, kwargs: dict) -> Optional[Dict]:
    """ä»ç»“æœä¸­æå–tokenä½¿ç”¨ä¿¡æ¯"""
    token_info = {}

    # ä»ChatResultä¸­æå–tokenä½¿ç”¨
    if hasattr(result, 'llm_output') and result.llm_output:
        token_usage = result.llm_output.get('token_usage', {})
        if token_usage:
            token_info.update({
                "input_tokens": token_usage.get('prompt_tokens', 0),
                "output_tokens": token_usage.get('completion_tokens', 0),
                "total_tokens": token_usage.get('total_tokens', 0)
            })

    # ä»kwargsä¸­æå–ä¼šè¯å’Œåˆ†æç±»å‹ä¿¡æ¯
    token_info.update({
        "session_id": kwargs.get('session_id', 'unknown'),
        "analysis_type": kwargs.get('analysis_type', 'unknown')
    })

    # å¦‚æœæœ‰token trackerï¼Œå°è¯•è®¡ç®—æˆæœ¬
    try:
        from tradingagents.config.config_manager import token_tracker
        if token_info.get('total_tokens', 0) > 0:
            # è¿™é‡Œå¯ä»¥æ ¹æ®providerå’Œmodelè®¡ç®—æˆæœ¬
            # æš‚æ—¶è®¾ä¸º0ï¼Œå®é™…æˆæœ¬ç”±token_trackerè®¡ç®—
            token_info["cost"] = 0.0
    except ImportError:
        pass

    return token_info if token_info else None


def log_model_invoke(provider: str, model: str = None):
    """ä¸“é—¨ç”¨äºmodel.invoke()è°ƒç”¨çš„è£…é¥°å™¨"""
    return log_ai_call(
        provider=provider,
        model=model,
        log_input=True,
        log_output=True,
        log_tokens=True,
        debug_level="INFO"
    )


def log_chat_completion(provider: str, model: str = None):
    """ä¸“é—¨ç”¨äºèŠå¤©å®Œæˆè°ƒç”¨çš„è£…é¥°å™¨"""
    return log_ai_call(
        provider=provider,
        model=model,
        log_input=True,
        log_output=True,
        log_tokens=True,
        debug_level="INFO"
    )


def log_ai_debug():
    """è°ƒè¯•æ¨¡å¼çš„AIè°ƒç”¨æ—¥å¿—è£…é¥°å™¨ï¼Œè®°å½•æ‰€æœ‰è¯¦ç»†ä¿¡æ¯"""
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            # è‡ªåŠ¨æ£€æµ‹providerå’Œmodel
            provider = "unknown"
            model = "unknown"

            if args and hasattr(args[0], '__class__'):
                class_name = args[0].__class__.__name__
                if 'DeepSeek' in class_name:
                    provider = "deepseek"
                elif 'OpenAI' in class_name:
                    provider = "openai"
                elif 'Anthropic' in class_name:
                    provider = "anthropic"
                elif 'DashScope' in class_name:
                    provider = "dashscope"
                elif 'Google' in class_name:
                    provider = "google"

                if hasattr(args[0], 'model'):
                    model = args[0].model
                elif hasattr(args[0], 'model_name'):
                    model = args[0].model_name

            # åº”ç”¨è¯¦ç»†æ—¥å¿—è®°å½•
            return log_ai_call(
                provider=provider,
                model=model,
                log_input=True,
                log_output=True,
                log_tokens=True,
                debug_level="DEBUG"
            )(func)(*args, **kwargs)

        return wrapper
    return decorator


# ä¾¿æ·å‡½æ•°ï¼šè®°å½•AIè°ƒç”¨æ‘˜è¦
def log_ai_call_summary(
    call_id: str,
    provider: str,
    model: str,
    function_name: str,
    success: bool,
    duration: float,
    input_tokens: int = 0,
    output_tokens: int = 0,
    cost: float = 0.0,
    **extra_info
):
    """è®°å½•AIè°ƒç”¨æ‘˜è¦ä¿¡æ¯"""
    summary = {
        "call_id": call_id,
        "provider": provider,
        "model": model,
        "function": function_name,
        "success": success,
        "duration": duration,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "total_tokens": input_tokens + output_tokens,
        "cost": cost,
        "timestamp": datetime.now().isoformat(),
        **extra_info
    }

    status = "æˆåŠŸ" if success else "å¤±è´¥"
    ai_logger.info(
        f"ğŸ“Š [AIè°ƒç”¨æ‘˜è¦] {provider}/{model} - {status} [ID: {call_id}]",
        extra=summary
    )